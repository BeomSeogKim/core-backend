# 캐시

자주 사용되는 데이터를 빠르게 접근할 수 있는 임시 저장소이다. 원본 데이터 저장소보다 접근 속도가 빠른 곳에 데이터의 복사본을 저장해두고, 다음에 같은 데이터가 필요할 때 빠르게 제공하는 메커니즘이다.

## 캐시가 필요한 이유

**성능향상**

- 응답 시간 단축 : 느린 저장소 (DB, 디스크)에 접근하는 대신 빠른 메모리에서 데이터를 가져옴
- 처리량 증가 : 같은 시간에 더 많은 요청을 처리할 수 있음

**비용 절감**

- DB 부하 감소 : 반복적인 DB 쿼리를 줄여 DB 서버의 부담을 낮춤
- 네트워크 트래픽 감소 : 원격 서버 호출 횟수를 줄임

## 캐시의 종류

### 1. 하드웨어 캐시

CPU 캐시 (L1, L2, L3)

```
CPU 코어
  ↓ (가장 빠름, 가장 작음)
L1 캐시 (수십 KB) - 1~2 사이클
  ↓
L2 캐시 (수백 KB) - 10~20 사이클
  ↓
L3 캐시 (수 MB) - 40~50 사이클
  ↓
메인 메모리 (수 GB) - 100~300 사이클
  ↓
디스크 (수 TB) - 수백만 사이클
```

### 2. 소프트웨어 캐시

애플리케이션 레벨 캐시

- 로컬 캐시 (In-Memory Cache)
  - 애플리케이션 프로세스 내부의 메모리에 데이터 저장
  - Java의 ConcurrentHashMap, Guava Cache, Caffeine
  - 장점 : 매우 빠름 (네트워크 통신 X)
  - 단점 : 프로세스 종료 시 데이터 소실, 여러 서버간 공유 불가
- 분산 캐시 (Distributed Cache)
  - 별도의 캐시 서버에 데이터 저장
  - Redis, Memcached
  - 장점 : 여러 애플리케이션 서버가 공유 가능하며 영속성이 가능
  - 단점 : 네트워크 지연 존재

이 외에도 데이터베이스 캐시, 웹 캐시 등이 존재한다.

## 캐시 동작 원리

```
1. 클라이언트가 데이터 요청
   ↓
2. 캐시에 데이터 있는지 확인
   ↓
3-1. Cache Hit (캐시에 있음)
   → 캐시에서 바로 반환

3-2. Cache Miss (캐시에 없음)
   → 원본 저장소(DB)에서 조회
   → 조회한 데이터를 캐시에 저장
   → 클라이언트에 반환
```

## 캐시 패턴

**읽기 전략**
- Cache Aside(Lazy Loading)
  - 데이터가 필요한 시점에만 데이터를 캐시에 적재함

  1. 먼저 캐시에서 데이터를 조회
  2. 캐시에 데이터가 있다면 즉시 반환
  3. 캐시에 데이터가 없다면 DB에서 데이터를 조회한 후, 캐시에 해당 데이터를 저장하고 반환

- Read Through
  - 캐시 시스템이 자동으로 DB에서 데이터를 조회하고 캐시에 적재하는 방식

  1. 먼저 캐시에서 데이터를 조회
  2. 캐시에 데이터가 있다면 즉시 반환
  3. 캐시에 데이터가 없다면 **캐시 시스템이 DB에서 데이터를 조회** 후 해당 데이터를 캐시에 저장 후 반환

**쓰기 전략**
- Write Around Aside
  - 쓰기 요청이 들어오면 DB에만 데이터를 저장하고, 캐시는 건드리지 않는 방식

  1. 데이터 쓰기 요청
  2. DB에만 데이터를 변경

- Wrtie Through
  - 캐시와 DB 모두에 데이터를 동시에 저장하는 방식

  1. 데이터 쓰기 요청
  2. 캐시에 먼저 변경 내용을 반영
  3. 이후 DB에 변경 내용을 반영

- Write Back
  - 쓰기 요청을 캐시에만 반영하고, DB에는 비동기적으로 저장하는 방식

  1. 데이터 쓰기 요청
  2. 캐시에 먼저 변경 내용 반영
  3. 이후 DB에 변경 내용을 비동기적으로 반영

